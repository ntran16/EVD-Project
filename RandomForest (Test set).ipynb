{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/ Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hulabapp\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import RandomizedLogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import brew\n",
    "from brew.base import Ensemble\n",
    "from brew.combination.combiner import Combiner\n",
    "from brew.stacking.stacker import EnsembleStack\n",
    "from brew.stacking.stacker import EnsembleStackClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import (preprocessing, metrics, cross_validation)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from numba import autojit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = 'D:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#upsample minority class\n",
    "\n",
    "# def upsample(data, labels):\n",
    "#     \"\"\"\n",
    "#     This function is to upsample the data for the under-repressenting class with replacement. \n",
    "#     The result will be a matrix with the same amount of species for each class.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     from collections import defaultdict\n",
    "#     import random\n",
    "\n",
    "#     label_indices = defaultdict(lambda: list())\n",
    "#     for idx, label in enumerate(labels):\n",
    "#         label_indices[label].append(idx)\n",
    "\n",
    "#     largest_class_size = max(map(lambda l: len(l), label_indices.values()))\n",
    "\n",
    "#     upsampled_indices = []\n",
    "#     for label, indices in label_indices.items():\n",
    "#         sampled_indices = indices[:]\n",
    "#         while len(sampled_indices) < largest_class_size:\n",
    "#             sampled_indices.append(random.choice(indices))\n",
    "#         upsampled_indices.extend(sampled_indices)\n",
    "\n",
    "#     upsampled_labels = labels[upsampled_indices]\n",
    "#     upsampled_data = data[upsampled_indices, :]\n",
    "\n",
    "#     return upsampled_data, upsampled_labels\n",
    "\n",
    "# # find optimal cutoff using Youdel index\n",
    "# def Find_Optimal_Cutoff(target, predicted):\n",
    "#     \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "#     Input:\n",
    "#     target values \n",
    "#     predicted values\n",
    "    \n",
    "#     Returns\n",
    "#     optimal cutoff value\n",
    "#     \"\"\"\n",
    "#     fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "#     i = np.arange(len(tpr)) \n",
    "#     roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "#     roc_t = roc.ix[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "#     return list(roc_t['threshold']) \n",
    "\n",
    "# pretty plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@autojit\n",
    "def train_randomforest(X,Y):\n",
    "    '''This function perform logistic regression training using cross-validation'''\n",
    "    start = time.time()\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    fold = StratifiedKFold(Y, n_folds=10, shuffle=True, random_state=0)\n",
    "    SP = StratifiedShuffleSplit(n_splits=50, test_size=.2, random_state=0)\n",
    "\n",
    "    grid = {\"n_estimators\": [50, 100, 200, 300],\n",
    "              \"max_depth\": [2,4,6,8,10],\n",
    "              \"max_features\": [1, 2, 3, 4, 5, 6],\n",
    "              \"max_leaf_nodes\": [2,4,6,8,10],\n",
    "              \"min_samples_leaf\": [2,4,6,8,10],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"class_weight\":['balanced']} \n",
    "\n",
    "# Using RF CV (cross validation search for RF) and report ROC_AUC score\n",
    "    clf = RandomForestClassifier(oob_score = True, random_state = 0)\n",
    "    searchCV = RandomizedSearchCV(clf, grid,n_iter = 200, scoring='roc_auc', cv=SP, n_jobs = -1)\n",
    "\n",
    "    searchCV.fit(X, Y)\n",
    "\n",
    "    cvs_score = searchCV.cv_results_['mean_test_score'][searchCV.best_index_]\n",
    "    cvs_std = searchCV.cv_results_['std_test_score'][searchCV.best_index_]\n",
    "    param = searchCV.cv_results_['params'][searchCV.best_index_]\n",
    "\n",
    "#     print(cvs_score,cvs_std)\n",
    "\n",
    "    end = time.time()\n",
    "    print (end - start)\n",
    "\n",
    "#     grid_scores = searchCV.grid_scores_\n",
    "#     top_scores_logistic = sorted(grid_scores,\n",
    "#                         key=itemgetter(1),\n",
    "#                         reverse=True)[:5]\n",
    "#     for i, score in enumerate(top_scores_logistic):\n",
    "#         print(\"Model with rank: {0}\".format(i + 1))\n",
    "#         print((\"Mean validation score: \"\n",
    "#                \"{0:.3f} (std: {1:.3f})\").format(\n",
    "#                score.mean_validation_score,\n",
    "#                np.std(score.cv_validation_scores)))\n",
    "#         print(\"Parameters: {0}\".format(score.parameters))\n",
    "#         print(\"\")\n",
    "    \n",
    "    return param, cvs_score, cvs_std\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Cross Validation and dump model to a .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.78108954429626\n",
      "113.69398736953735\n",
      "110.44951391220093\n",
      "109.83797240257263\n",
      "116.60977101325989\n",
      "111.15251064300537\n",
      "111.93145155906677\n",
      "119.19802665710449\n",
      "113.520911693573\n",
      "114.43068504333496\n",
      "113.49772334098816\n",
      "115.13772892951965\n",
      "106.63792538642883\n",
      "115.68576169013977\n",
      "108.93970346450806\n",
      "110.15328574180603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hulabapp\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.5421974658966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hulabapp\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.0472207069397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hulabapp\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.79359602928162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hulabapp\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.00037360191345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hulabapp\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.36111164093018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hulabapp\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.51668977737427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hulabapp\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 7 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.83255982398987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hulabapp\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 6 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.03317713737488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "cv_param = []\n",
    "cv_score = []\n",
    "cv_std = []\n",
    "for count in range(1,25):\n",
    "    X = np.genfromtxt('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TrainX.csv' %(server,count), delimiter=',')\n",
    "    Y = np.genfromtxt('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TrainY.csv'% (server,count), delimiter=',')\n",
    "    score = train_randomforest(X,Y)\n",
    "    clf = RandomForestClassifier(**score[0],oob_score = True, random_state = 0).fit(X,Y)\n",
    "    joblib.dump(clf, '%s/Dropbox/Rotation 3 Project/Models/RF/hour%02d.pkl' %(server,count)) \n",
    "    cv_param.append(score[0])\n",
    "    cv_score.append(score[1])\n",
    "    cv_std.append(score[2])\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/RF_CV_score.csv' %server, cv_score, delimiter=',')\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/RF_CV_std.csv' %server, cv_std, delimiter=',')\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/RF_CV_param.txt'%server, cv_param, delimiter=',', fmt='%s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF OOB Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score = []\n",
    "for count in range(1,25):\n",
    "    X_train = pd.read_csv('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TrainX.csv' %(server,count), header = None)\n",
    "    Y_train = pd.read_csv('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TrainY.csv'%(server,count), header = None)\n",
    "\n",
    "    clf = joblib.load('%s/Dropbox/Rotation 3 Project/Models/RF/hour%02d.pkl' %(server,count))\n",
    "    oob_error = clf.oob_score_\n",
    "    roc_auc_score.append(oob_error)\n",
    "\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/RF_outofbag_ACCUscore.csv'%server, roc_auc_score, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81578947368421051"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oob_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the 20% hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=10, max_features=2,\n",
      "            max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=8, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.384615384615\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=4, max_features=2,\n",
      "            max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.666666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=2, max_features=6,\n",
      "            max_leaf_nodes=6, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.397435897436\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=8, max_features=2,\n",
      "            max_leaf_nodes=8, min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=200, n_jobs=1, oob_score=True, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "0.512820512821\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=4, max_features=3,\n",
      "            max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.615384615385\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=10, max_features=1,\n",
      "            max_leaf_nodes=6, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.615384615385\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=6, max_features=5,\n",
      "            max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.333333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=6, max_features=6,\n",
      "            max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.0769230769231\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=10, max_features=5,\n",
      "            max_leaf_nodes=2, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.371794871795\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=4, max_features=5,\n",
      "            max_leaf_nodes=6, min_impurity_split=1e-07, min_samples_leaf=4,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=50, n_jobs=1, oob_score=True, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "0.722222222222\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=10, max_features=4,\n",
      "            max_leaf_nodes=2, min_impurity_split=1e-07, min_samples_leaf=4,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=50, n_jobs=1, oob_score=True, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "0.5\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=6, max_features=5,\n",
      "            max_leaf_nodes=4, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.166666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=10, max_features=5,\n",
      "            max_leaf_nodes=2, min_impurity_split=1e-07, min_samples_leaf=6,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=300, n_jobs=1, oob_score=True, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "0.111111111111\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=4, max_features=5,\n",
      "            max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.181818181818\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=4, max_features=6,\n",
      "            max_leaf_nodes=4, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.625\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=4, max_features=1,\n",
      "            max_leaf_nodes=6, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.333333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=10, max_features=6,\n",
      "            max_leaf_nodes=2, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.833333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=6, max_features=6,\n",
      "            max_leaf_nodes=6, min_impurity_split=1e-07, min_samples_leaf=6,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=200, n_jobs=1, oob_score=True, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "0.909090909091\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=6, max_features=5,\n",
      "            max_leaf_nodes=8, min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=300, n_jobs=1, oob_score=True, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "0.431818181818\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=10, max_features=4,\n",
      "            max_leaf_nodes=8, min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=50, n_jobs=1, oob_score=True, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "0.25\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=8, max_features=4,\n",
      "            max_leaf_nodes=4, min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=50, n_jobs=1, oob_score=True, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "0.5\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=4, max_features=4,\n",
      "            max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.9\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=6, max_features=1,\n",
      "            max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=6, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
      "0.388888888889\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=8, max_features=1,\n",
      "            max_leaf_nodes=2, min_impurity_split=1e-07, min_samples_leaf=6,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=50, n_jobs=1, oob_score=True, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "0.1875\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'D:/Dropbox/Rotation 3 Project/Result/RF_holdouttest_AUCscore.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c508795829fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/Dropbox/Rotation 3 Project/Result/RF_holdouttest_AUCscore.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'D:/Dropbox/Rotation 3 Project/Result/RF_holdouttest_AUCscore.csv'"
     ]
    }
   ],
   "source": [
    "roc_auc_score = []\n",
    "for count in range(1,25):\n",
    "    X_test1 = pd.read_csv('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TestX.csv' %(server,count), header = None)\n",
    "    Y_test1 = pd.read_csv('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TestY.csv'%(server,count), header = None)\n",
    "\n",
    "    clf = joblib.load('%s/Dropbox/Rotation 3 Project/Models/RF/hour%02d.pkl' %(server,count))\n",
    "    print(clf)\n",
    "    Y_proba = clf.predict_proba(X_test1)\n",
    "    Y_predict = clf.predict(X_test1)\n",
    "\n",
    "#     from sklearn.metrics import confusion_matrix\n",
    "#     print(confusion_matrix(Y_test1, Y_predict))\n",
    "\n",
    "    # fpr, tpr, thresholds = roc_curve(Y_test, Y_df)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test1, Y_proba[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_score.append(roc_auc)\n",
    "    print(roc_auc)\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/RF_holdouttest_AUCscore.csv'%server, roc_auc_score, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the Columbia patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:534: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:96: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(dx < 0):\n"
     ]
    }
   ],
   "source": [
    "roc_auc_score = []\n",
    "for count in range(1,25):\n",
    "    datapath = '%s/Dropbox/Rotation 3 Project/Data/ColumbiaTest/featurematrixandtarget_%02dh' %(server,count)\n",
    "    datacontent = sio.loadmat(datapath)\n",
    "\n",
    "    X_test2 = datacontent['featm']\n",
    "    X_test2 = np.nan_to_num(X_test2) # replace nan with 0\n",
    "    nsubjects = X_test2.shape[0]\n",
    "\n",
    "    Yv = datacontent['y']\n",
    "    Y_test2 = np.ravel(Yv)\n",
    "\n",
    "    clf = joblib.load('%s/Dropbox/Rotation 3 Project/Models/RF/hour%02d.pkl' %(server,count))\n",
    "    Y_proba = clf.predict_proba(X_test2)\n",
    "    Y_predict = clf.predict(X_test2)\n",
    "\n",
    "    # from sklearn.metrics import confusion_matrix\n",
    "    # print(confusion_matrix(Y_test2, Y_predict))\n",
    "\n",
    "    # fpr, tpr, thresholds = roc_curve(Y_test, Y_df)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test2, Y_proba[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_score.append(roc_auc)\n",
    "\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/RF_columbiatest_AUCscore.csv'%server, roc_auc_score, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the delayed shunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "for count in range(1,25):\n",
    "    datapath = '%s/Dropbox/Rotation 3 Project/Data/DelayedShuntTest/featurematrixandtarget_%02dh' %(server,count)\n",
    "    datacontent = sio.loadmat(datapath)\n",
    "\n",
    "    X_test3 = datacontent['featm']\n",
    "    X_test3 = np.nan_to_num(X_test3) # replace nan with 0\n",
    "    nsubjects = X_test3.shape[0]\n",
    "\n",
    "    Yv = datacontent['y']\n",
    "    Y_test3 = np.ravel(Yv)\n",
    "\n",
    "    clf = joblib.load('%s/Dropbox/Rotation 3 Project/Models/RF/hour%02d.pkl' %(server,count))\n",
    "    Y_proba = clf.predict_proba(X_test3)\n",
    "    s = clf.score(X_test3, Y_test3)\n",
    "    score.append(s)\n",
    "\n",
    "    # from sklearn.metrics import confusion_matrix\n",
    "    # print(confusion_matrix(Y_test2, Y_predict))\n",
    "\n",
    "#     roc_auc_score = []\n",
    "#     # fpr, tpr, thresholds = roc_curve(Y_test, Y_df)\n",
    "#     fpr, tpr, thresholds = roc_curve(Y_test2, Y_proba[:,1])\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     roc_auc_score.append(roc_auc)\n",
    "\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/RF_delayshunt_ACCUscore.csv' %server, score, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
