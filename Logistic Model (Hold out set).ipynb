{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/ Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import RandomizedLogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import brew\n",
    "from brew.base import Ensemble\n",
    "from brew.combination.combiner import Combiner\n",
    "from brew.stacking.stacker import EnsembleStack\n",
    "from brew.stacking.stacker import EnsembleStackClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import (preprocessing, metrics, cross_validation)\n",
    "\n",
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change name of the location of Dropbox Folder.\n",
    "server = 'H:/MatlabProjects/Nate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#upsample minority class\n",
    "\n",
    "def upsample(data, labels):\n",
    "    \"\"\"\n",
    "    This function is to upsample the data for the under-repressenting class with replacement. \n",
    "    The result will be a matrix with the same amount of species for each class.\n",
    "    \"\"\"\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    import random\n",
    "\n",
    "    label_indices = defaultdict(lambda: list())\n",
    "    for idx, label in enumerate(labels):\n",
    "        label_indices[label].append(idx)\n",
    "\n",
    "    largest_class_size = max(map(lambda l: len(l), label_indices.values()))\n",
    "\n",
    "    upsampled_indices = []\n",
    "    for label, indices in label_indices.items():\n",
    "        sampled_indices = indices[:]\n",
    "        while len(sampled_indices) < largest_class_size:\n",
    "            sampled_indices.append(random.choice(indices))\n",
    "        upsampled_indices.extend(sampled_indices)\n",
    "\n",
    "    upsampled_labels = labels[upsampled_indices]\n",
    "    upsampled_data = data[upsampled_indices, :]\n",
    "\n",
    "    return upsampled_data, upsampled_labels\n",
    "\n",
    "# find optimal cutoff using Youdel index\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Input:\n",
    "    target values \n",
    "    predicted values\n",
    "    \n",
    "    Returns\n",
    "    optimal cutoff value\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.ix[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n",
    "# pretty plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_logistic(X,Y):\n",
    "    '''This function perform logistic regression training using cross-validation'''\n",
    "    start = time.time()\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    fold = StratifiedKFold(Y, n_folds=10, shuffle=True, random_state=0)\n",
    "    SP = StratifiedShuffleSplit(n_splits=50, test_size=.2, random_state=0)\n",
    "\n",
    "    grid = {'penalty':['l2'],'fit_intercept':[True, False],'C': np.power(10.0, np.linspace(-15, 15, 200)), 'solver':['newton-cg','liblinear','lbfgs'],'class_weight':['balanced']}\n",
    "    #     score = None\n",
    "    # Using LogisticRegressionCV (cross validation search for Logistic regression) and report ROC_AUC score\n",
    "    clf = LogisticRegression(random_state=0, tol=.001)\n",
    "    searchCV = RandomizedSearchCV(clf, grid,n_iter = 1000, scoring='roc_auc', cv=SP, n_jobs = -1)\n",
    "\n",
    "    searchCV.fit(X, Y)\n",
    "\n",
    "    cvs_score = searchCV.cv_results_['mean_test_score'][searchCV.best_index_]\n",
    "    cvs_std = searchCV.cv_results_['std_test_score'][searchCV.best_index_]\n",
    "    param = searchCV.cv_results_['params'][searchCV.best_index_]\n",
    "\n",
    "#     print(cvs_score,cvs_std)\n",
    "\n",
    "    end = time.time()\n",
    "    print (end - start)\n",
    "\n",
    "#     grid_scores = searchCV.grid_scores_\n",
    "#     top_scores_logistic = sorted(grid_scores,\n",
    "#                         key=itemgetter(1),\n",
    "#                         reverse=True)[:5]\n",
    "#     for i, score in enumerate(top_scores_logistic):\n",
    "#         print(\"Model with rank: {0}\".format(i + 1))\n",
    "#         print((\"Mean validation score: \"\n",
    "#                \"{0:.3f} (std: {1:.3f})\").format(\n",
    "#                score.mean_validation_score,\n",
    "#                np.std(score.cv_validation_scores)))\n",
    "#         print(\"Parameters: {0}\".format(score.parameters))\n",
    "#         print(\"\")\n",
    "    \n",
    "    return param, cvs_score, cvs_std\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Cross Validation and dump model to a .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.501932859420776\n",
      "56.084574937820435\n",
      "70.82893919944763\n",
      "70.09731769561768\n",
      "63.98280382156372\n",
      "63.963582277297974\n",
      "65.17745089530945\n",
      "58.21783995628357\n",
      "61.18360638618469\n",
      "70.73594307899475\n",
      "59.10253047943115\n",
      "61.09845185279846\n",
      "59.855053186416626\n",
      "59.92598104476929\n",
      "63.29697561264038\n",
      "63.44581174850464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.86022877693176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.30455875396729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.64108204841614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.15948343276978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.67080020904541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.31489682197571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 7 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.09549689292908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 6 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.13296556472778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "cv_param = []\n",
    "cv_score = []\n",
    "cv_std = []\n",
    "for count in range(1,25):\n",
    "    X = np.genfromtxt('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TrainX.csv' %(server,count), delimiter=',')\n",
    "    Y = np.genfromtxt('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TrainY.csv'% (server,count), delimiter=',')\n",
    "    score = train_logistic(X,Y)\n",
    "    clf = LogisticRegression(**score[0],random_state = 0, tol = .001).fit(X,Y)\n",
    "    joblib.dump(clf, '%s/Dropbox/Rotation 3 Project/Models/Logistic/hour%02d.pkl' %(server,count)) \n",
    "    cv_param.append(score[0])\n",
    "    cv_score.append(score[1])\n",
    "    cv_std.append(score[2])\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/Logistic_CV_score.csv' %server, cv_score, delimiter=',')\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/Logistic_CV_std.csv' %server, cv_std, delimiter=',')\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/Logistic_CV_param.txt' %server, cv_param, delimiter=',', fmt='%s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find optimal cutoff using Youden's index and save them for each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut_off = []\n",
    "for count in range(1,25):\n",
    "    X = np.genfromtxt('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TrainX.csv' % (server,count), delimiter=',')\n",
    "    Y = np.genfromtxt('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TrainY.csv'% (server,count), delimiter=',')\n",
    "    clf = joblib.load('%s/Dropbox/Rotation 3 Project/Models/Logistic/hour%02d.pkl' %(server,count)) \n",
    "    Y_proba = clf.predict_proba(X)\n",
    "    threshold = Find_Optimal_Cutoff(Y, Y_proba[:,1])\n",
    "    cut_off.append(threshold)\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/cut off log.csv' %server, cut_off, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the 20% hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score = []\n",
    "for count in range(1,25):\n",
    "    X_test1 = pd.read_csv('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TestX.csv' %(server,count), header = None)\n",
    "    Y_test1 = pd.read_csv('%s/Dropbox/Rotation 3 Project/TrainTest/%02d/TestY.csv'%(server,count), header = None)\n",
    "\n",
    "    clf = joblib.load('%s/Dropbox/Rotation 3 Project/Models/Logistic/hour%02d.pkl' %(server,count))\n",
    "    Y_proba = clf.predict_proba(X_test1)\n",
    "    Y_predict = clf.predict(X_test1)\n",
    "\n",
    "#     from sklearn.metrics import confusion_matrix\n",
    "#     print(confusion_matrix(Y_test1, Y_predict))\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test1, Y_proba[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_score.append(roc_auc)\n",
    "\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/Log_holdouttest_AUCscore.csv' %server, roc_auc_score, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the Columbia patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:534: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "C:\\Users\\ntran\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py:96: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(dx < 0):\n"
     ]
    }
   ],
   "source": [
    "roc_auc_score = []\n",
    "for count in range(1,25):\n",
    "    datapath = '%s/Dropbox/Rotation 3 Project/Data/ColumbiaTest/featurematrixandtarget_%02dh' %(server,count)\n",
    "    datacontent = sio.loadmat(datapath)\n",
    "\n",
    "    X_test2 = datacontent['featm']\n",
    "    X_test2 = np.nan_to_num(X_test2) # replace nan with 0\n",
    "    nsubjects = X_test2.shape[0]\n",
    "\n",
    "    Yv = datacontent['y']\n",
    "    Y_test2 = np.ravel(Yv)\n",
    "\n",
    "    clf = joblib.load('%s/Dropbox/Rotation 3 Project/Models/Logistic/hour%02d.pkl' %(server,count))\n",
    "    Y_proba = clf.predict_proba(X_test2)\n",
    "    Y_predict = clf.predict(X_test2)\n",
    "\n",
    "    # from sklearn.metrics import confusion_matrix\n",
    "    # print(confusion_matrix(Y_test2, Y_predict))\n",
    "\n",
    "    # fpr, tpr, thresholds = roc_curve(Y_test, Y_df)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test2, Y_proba[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_score.append(roc_auc)\n",
    "\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/Log_columbiatest_AUCscore.csv' %server, roc_auc_score, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the delayshunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "for count in range(1,25):\n",
    "    datapath = '%s/Dropbox/Rotation 3 Project/Data/DelayedShuntTest/featurematrixandtarget_%02dh' %(server,count)\n",
    "    datacontent = sio.loadmat(datapath)\n",
    "\n",
    "    X_test3 = datacontent['featm']\n",
    "    X_test3 = np.nan_to_num(X_test3) # replace nan with 0\n",
    "    nsubjects = X_test3.shape[0]\n",
    "\n",
    "    Yv = datacontent['y']\n",
    "    Y_test3 = np.ravel(Yv)\n",
    "\n",
    "    clf = joblib.load('%s/Dropbox/Rotation 3 Project/Models/Logistic/hour%02d.pkl' %(server,count))\n",
    "    Y_proba = clf.predict_proba(X_test3)\n",
    "    s = clf.score(X_test3, Y_test3)\n",
    "    score.append(s)\n",
    "\n",
    "    # from sklearn.metrics import confusion_matrix\n",
    "    # print(confusion_matrix(Y_test2, Y_predict))\n",
    "\n",
    "#     roc_auc_score = []\n",
    "#     # fpr, tpr, thresholds = roc_curve(Y_test, Y_df)\n",
    "#     fpr, tpr, thresholds = roc_curve(Y_test2, Y_proba[:,1])\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     roc_auc_score.append(roc_auc)\n",
    "\n",
    "np.savetxt('%s/Dropbox/Rotation 3 Project/Result/Log_delayshunt_ACCUscore.csv' %server, score, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
